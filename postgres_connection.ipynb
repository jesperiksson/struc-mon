{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TFIO_GOST_DATABASE_NAME=gost\n",
      "env: TFIO_GOST_DATABASE_HOST=127.0.0.1:5050\n",
      "env: TFIO_GOST_DATABASE_PORT=5432\n",
      "env: TFIO_GOST_DATABASE_USER=postgres\n",
      "env: TFIO_GOST_DATABASE_PASS=postgres\n"
     ]
    }
   ],
   "source": [
    "%env TFIO_GOST_DATABASE_NAME=gost\n",
    "%env TFIO_GOST_DATABASE_HOST=127.0.0.1:5050\n",
    "%env TFIO_GOST_DATABASE_PORT=5432\n",
    "%env TFIO_GOST_DATABASE_USER=postgres\n",
    "%env TFIO_GOST_DATABASE_PASS=postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint=\"postgresql://{}:{}@{}?port={}&dbname={}\".format(\n",
    "    os.environ['TFIO_GOST_DATABASE_USER'],\n",
    "    os.environ['TFIO_GOST_DATABASE_PASS'],\n",
    "    os.environ['TFIO_GOST_DATABASE_HOST'],\n",
    "    os.environ['TFIO_GOST_DATABASE_PORT'],\n",
    "    os.environ['TFIO_GOST_DATABASE_NAME'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        table_names = {\n",
    "            'strain1' : 'sensor_00158d00000e0ee5',\n",
    "            'acc1' : 'sensor_00158d00000e0fe9',\n",
    "            'acc2' : 'sensor_00158d00000e054c',\n",
    "            'incl' : 'sensor_00158d00000e1024',\n",
    "            'temp' : 'sensor_00158d00000e047b',\n",
    "            'strain2': 'sensor_000000008bff4366'\n",
    "        }\n",
    "        self.table_names = table_names\n",
    "        \n",
    "        self.column_names = {\n",
    "            table_names['strain1'] : ['id','ts','ch_mv0','ch_mv1','ch_mv2','ch_mv3'],\n",
    "            table_names['acc1'] : ['id','ts','ch_x','ch_y','ch_z'],\n",
    "            table_names['acc2'] : ['id','ts','ch_x','ch_y','ch_z'],\n",
    "            table_names['incl'] : ['id','ts','ch_x','ch_y'],\n",
    "            table_names['temp'] : ['id','ts','ch_temperature'],\n",
    "            table_names['strain2'] : ['id','ts','ch_mv0','ch_mv0_379']\n",
    "        }\n",
    "\n",
    "        self.schema = 'v1'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings():\n",
    "    def __init__(self):\n",
    "        self.sensors = ['acc1']\n",
    "        self.n_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_select():\n",
    "    select_command = ''\n",
    "    for sensor in settings.sensors:\n",
    "        table = config.table_names[sensor]\n",
    "        for column in config.column_names[table]:\n",
    "            select_command+=table+'.'+column+' ,' # schema? alias?\n",
    "    return select_command[:-1]\n",
    "\n",
    "def generate_query():\n",
    "    select_command = f\"SELECT {generate_select()}\"\n",
    "    from_command =  f\"FROM {config.schema}.{(', '+config.schema+'.').join([config.table_names[sensor] for sensor in settings.sensors])} \"\n",
    "    where_clause = f\"WHERE {config.schema}.{config.table_names[settings.sensors[0]]}.id < {settings.n_samples}\"\n",
    "    query = select_command + from_command + where_clause\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT strain.ch_mv0, strain.id FROM v1.sensor_000000008bff43b6 strain WHERE strain.id < 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT sensor_00158d00000e0fe9.id ,sensor_00158d00000e0fe9.ch_x FROM v1.sensor_00158d00000e0fe9 WHERE v1.sensor_00158d00000e0fe9.id < 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT sensor_00158d00000e0fe9.id ,sensor_00158d00000e0fe9.ts ,sensor_00158d00000e0fe9.ch_x ,sensor_00158d00000e0fe9.ch_y ,sensor_00158d00000e0fe9.ch_z FROM v1.sensor_00158d00000e0fe9 WHERE v1.sensor_00158d00000e0fe9.id < 10'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "OID of data type 1700 is not supported [Op:IO>SqlIterableInit]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b5c4916e23e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dataset = tfio.experimental.IODataset.from_sql(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow_io/core/python/experimental/io_dataset_ops.py\u001b[0m in \u001b[0;36mfrom_sql\u001b[0;34m(cls, query, endpoint, spec)\u001b[0m\n\u001b[1;32m    236\u001b[0m           \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mIODataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msql_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSQLIODataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow_io/core/python/experimental/sql_dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query, endpoint, spec, internal)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0minternal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             resource, count, fields, dtypes = core_ops.io_sql_iterable_init(\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mio_sql_iterable_init\u001b[0;34m(input, endpoint, container, shared_name, name)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mio_sql_iterable_init_eager_fallback\u001b[0;34m(input, endpoint, container, shared_name, name, ctx)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: OID of data type 1700 is not supported [Op:IO>SqlIterableInit]"
     ]
    }
   ],
   "source": [
    "dataset = tfio.experimental.IODataset.from_sql(\n",
    "    query = query,\n",
    "    endpoint = endpoint\n",
    ")\n",
    "\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.15625>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.24219>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.30469>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=3>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.25>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.125>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=5>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.14844>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=6>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.34375>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=7>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.16406>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=8>}\n",
      "{'ch_mv0': <tf.Tensor: shape=(), dtype=float32, numpy=8.30469>, 'id': <tf.Tensor: shape=(), dtype=int64, numpy=9>}\n"
     ]
    }
   ],
   "source": [
    "for element in dataset:\n",
    "    print(element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
